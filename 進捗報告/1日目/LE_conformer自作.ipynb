{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94488df2-cff8-45be-bede-444e38a59b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "class _ConvolutionModule(torch.nn.Module):\n",
    "    r\"\"\"LE_Conformer convolution module.\n",
    "\n",
    "    Args:\n",
    "        input_dim (int): input dimension.\n",
    "        num_channels (int): number of depthwise convolution layer input channels.\n",
    "        depthwise_kernel_size (int): kernel size of depthwise convolution layer.\n",
    "        dropout (float, optional): dropout probability. (Default: 0.0)\n",
    "        bias (bool, optional): indicates whether to add bias term to each convolution layer. (Default: ``False``)\n",
    "        use_group_norm (bool, optional): use GroupNorm rather than BatchNorm. (Default: ``False``)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,  # 入力の次元数\n",
    "        num_channels: int,  # 畳み込み層のチャンネル数\n",
    "        depthwise_kernel_size: int,  # 深さ方向の畳み込みのカーネルサイズ\n",
    "        dropout: float = 0.0,  # ドロップアウトの割合\n",
    "        bias: bool = False,  # バイアス項を使用するかどうか\n",
    "        use_group_norm: bool = False,  # GroupNormを使用するかどうか\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        # depthwise_kernel_sizeが奇数でなければならない理由は、'SAME'パディングを実現するためです。\n",
    "        if (depthwise_kernel_size - 1) % 2 != 0:\n",
    "            raise ValueError(\"depthwise_kernel_size must be odd to achieve 'SAME' padding.\")\n",
    "        # LayerNorm層\n",
    "        self.layer_norm = torch.nn.LayerNorm(input_dim)\n",
    "        # 畳み込み層と活性化関数を含むシーケンシャルなネットワーク\n",
    "        self.sequential = torch.nn.Sequential(\n",
    "            # Pointwise convolution: 入力次元から2倍のチャンネル数へ\n",
    "            torch.nn.Conv1d(\n",
    "                input_dim,\n",
    "                2 * num_channels,\n",
    "                kernel_size=1, # カーネルサイズ1はPointwiseConvの特徴\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "                bias=bias,\n",
    "            ),\n",
    "            # GLU活性化関数: チャンネル数を半分にする\n",
    "            torch.nn.GLU(dim=1),\n",
    "            # Depthwise convolution: 各チャンネル内での畳み込みを行う\n",
    "            torch.nn.Conv1d(\n",
    "                num_channels,\n",
    "                num_channels,\n",
    "                depthwise_kernel_size,\n",
    "                stride=1,\n",
    "                padding=(depthwise_kernel_size - 1) // 2,\n",
    "                groups=num_channels,\n",
    "                bias=bias,\n",
    "            ),\n",
    "            # GroupNormまたはBatchNorm層\n",
    "            torch.nn.GroupNorm(num_groups=1, num_channels=num_channels)\n",
    "            if use_group_norm\n",
    "            else torch.nn.BatchNorm1d(num_channels),\n",
    "            # SiLU活性化関数\n",
    "            torch.nn.SiLU(),\n",
    "            # Pointwise convolution: チャンネル数を元の入力次元に戻す\n",
    "            torch.nn.Conv1d(\n",
    "                num_channels,\n",
    "                input_dim,\n",
    "                kernel_size=1, # カーネルサイズ1はPointwiseConvの特徴\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "                bias=bias,\n",
    "            ),\n",
    "            # ドロップアウト層\n",
    "            torch.nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        r\"\"\"\n",
    "        Args:\n",
    "            input (torch.Tensor): with shape `(L,B, D)`.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: output, with shape `(L,B, D)`.\n",
    "        \"\"\"\n",
    "        x = self.layer_norm(input)\n",
    "        x = x.permute(1, 2,0) # 1D Convはlengthで畳み込みたい、Dはチャネルとしたいので(B,D,L)とする。\n",
    "        x = self.sequential(x)\n",
    "        return x.permute(2,0,1) #(L,B, D)に戻す。\n",
    "class SEBlock1D(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SEBlock1D, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "class Conv1DBlockWithSE(nn.Module):\n",
    "    def __init__(self, in_channels, depthwise_kernel_size):\n",
    "        super().__init__()\n",
    "        self.layer_norm = torch.nn.LayerNorm(in_channels)\n",
    "        self.conv = nn.Conv1d(in_channels, in_channels, \n",
    "                depthwise_kernel_size,\n",
    "                stride=1,\n",
    "                padding=(depthwise_kernel_size - 1) // 2,)\n",
    "        self.bn = nn.BatchNorm1d(in_channels)\n",
    "        self.swish = nn.SiLU()\n",
    "        self.se = SEBlock1D(in_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer_norm(x)\n",
    "        x = x.permute(1, 2, 0)\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.swish(x)\n",
    "        x = self.se(x)\n",
    "        x = x.permute(2, 0, 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class _FeedForwardModule(torch.nn.Module):# こちらは特に迷うこともなく論文そのままなのでコメントは割愛\n",
    "    r\"\"\"Positionwise feed forward layer.\n",
    "\n",
    "    Args:\n",
    "        input_dim (int): input dimension.\n",
    "        hidden_dim (int): hidden dimension.\n",
    "        dropout (float, optional): dropout probability. (Default: 0.0)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim: int, hidden_dim: int, depthwise_kernel_size: int, dropout: float = 0.0) -> None:\n",
    "        super().__init__()\n",
    "        self.layer_norm = nn.LayerNorm(input_dim)\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.activation = Conv1DBlockWithSE(hidden_dim,depthwise_kernel_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(hidden_dim, input_dim)\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        input = self.layer_norm(input)\n",
    "        hidden = self.fc1(input)\n",
    "        hidden = self.activation(hidden)\n",
    "        hidden = self.dropout(hidden)\n",
    "        output = self.fc2(hidden)\n",
    "        return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9978f84-0658-430e-a76d-8b6685929d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LE_ConformerLayer(torch.nn.Module):\n",
    "    r\"\"\"LE_Conformer layer that constitutes LE_Conformer.\n",
    "\n",
    "    Args:\n",
    "        input_dim (int): input dimension.\n",
    "        ffn_dim (int): hidden layer dimension of feedforward network.\n",
    "        num_attention_heads (int): number of attention heads.\n",
    "        depthwise_conv_kernel_size (int): kernel size of depthwise convolution layer.\n",
    "        dropout (float, optional): dropout probability. (Default: 0.0)\n",
    "        use_group_norm (bool, optional): use ``GroupNorm`` rather than ``BatchNorm1d``\n",
    "            in the convolution module. (Default: ``False``)\n",
    "        convolution_first (bool, optional): apply the convolution module ahead of\n",
    "            the attention module. (Default: ``False``)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        ffn_dim: int,\n",
    "        num_attention_heads: int,\n",
    "        depthwise_conv_kernel_size: int,\n",
    "        dropout: float = 0.0,\n",
    "        use_group_norm: bool = False,\n",
    "        convolution_first: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # 最初のフィードフォワードネットワークを定義します。このネットワークは、入力データを処理し、\n",
    "        # 隠れ層の次元をffn_dimに変換します。\n",
    "        self.ffn1 = _FeedForwardModule(input_dim, ffn_dim, depthwise_conv_kernel_size, dropout=dropout)\n",
    "\n",
    "        # レイヤーノーマライゼーションを定義します。これは、入力データのスケールを正規化するために使用されます。\n",
    "        self.self_attn_layer_norm = torch.nn.LayerNorm(input_dim)\n",
    "        # セルフアテンションメカニズムを定義します。これは、入力データの各部分が他の部分とどの程度関連しているかを学習します。\n",
    "        self.self_attn = torch.nn.MultiheadAttention(input_dim, num_attention_heads, dropout=dropout)\n",
    "        # ドロップアウトを定義します。これは、ネットワークの過学習を防ぐために使用されます。\n",
    "        self.self_attn_dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "        # 畳み込みモジュールを定義します。これは、入力データに畳み込みを適用し、特徴を抽出します。\n",
    "        self.conv_module = _ConvolutionModule(\n",
    "            input_dim=input_dim,\n",
    "            num_channels=input_dim,\n",
    "            depthwise_kernel_size=depthwise_conv_kernel_size,\n",
    "            dropout=dropout,\n",
    "            bias=True,\n",
    "            use_group_norm=use_group_norm,\n",
    "        )\n",
    "\n",
    "        # 二番目のフィードフォワードネットワークを定義します。このネットワークは、畳み込みモジュールとセルフアテンションメカニズムによって\n",
    "        # 処理し、出力の次元をinput_dimに戻します。\n",
    "        self.ffn2 = _FeedForwardModule(input_dim, ffn_dim, depthwise_conv_kernel_size, dropout=dropout)\n",
    "        # 最終的なレイヤーノーマライゼーションを定義します。これは、出力データのスケールを正規化するために使用されます。\n",
    "        self.final_layer_norm = torch.nn.LayerNorm(input_dim)\n",
    "        # 畳み込みモジュールをセルフアテンションメカニズムの前に適用するかどうかを決定します。\n",
    "        self.convolution_first = convolution_first\n",
    "\n",
    "    def _apply_convolution(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        # 入力データを保存します。これは後で残差接続を作成するために使用されます。\n",
    "        residual = input\n",
    "        # 入力データの次元を変更します。これは、畳み込みモジュールが適切に機能するために必要です。\n",
    "        input = input.transpose(0, 1)\n",
    "        # 畳み込みモジュールを適用します。これにより、入力データに畳み込みが適用され、特徴が抽出されます。\n",
    "        input = self.conv_module(input)\n",
    "        # 入力データの次元を元に戻します。これは、後続の処理ステップが適切に機能するために必要です。\n",
    "        input = input.transpose(0, 1)\n",
    "        # 残差接続を作成します。これは、ネットワークが入力データの重要な情報を保持できるようにするために使用されます。\n",
    "        input = residual + input\n",
    "        return input\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        r\"\"\"\n",
    "        Args:\n",
    "            input (torch.Tensor): input, with shape `(T, B, D)`.\n",
    "            key_padding_mask (torch.Tensor or None): key padding mask to use in self attention layer.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: output, with shape `(T, B, D)`.\n",
    "        \"\"\"\n",
    "        # 入力データを保存します。これは後で残差接続を作成するために使用されます。\n",
    "        residual = input\n",
    "        # 最初のフィードフォワードネットワークを適用します。これにより、入力データが処理され、隠れ層の次元がffn_dimに変換されます。\n",
    "        x = self.ffn1(input)\n",
    "        # スケールされた残差接続を作成します。これは、ネットワークが入力データの重要な情報を保持できるようにするために使用されます。\n",
    "        x = x * 0.5 + residual\n",
    "\n",
    "        # 畳み込みモジュールを最初に適用する場合、ここでそれを行います。\n",
    "        if self.convolution_first:\n",
    "            x = self._apply_convolution(x)\n",
    "\n",
    "        # 入力データを保存します。これは後で残差接続を作成するために使用されます。\n",
    "        residual = x\n",
    "        # レイヤーノーマライゼーションを適用します。これは、入力データのスケールを正規化するために使用されます。\n",
    "        x = self.self_attn_layer_norm(x)\n",
    "        # セルフアテンションメカニズムを適用します。これは、入力データの各部分が他の部分とどの程度関連しているかを学習します。\n",
    "        x, _ = self.self_attn(\n",
    "            query=x,\n",
    "            key=x,\n",
    "            value=x,\n",
    "            need_weights=False,\n",
    "            \n",
    "        )\n",
    "        # ドロップアウトを適用します。これは、ネットワークの過学習を防ぐために使用されます。\n",
    "        x = self.self_attn_dropout(x)\n",
    "        # 残差接続を作成します。これは、ネットワークが入力データの重要な情報を保持できるようにするために使用されます。\n",
    "        x = x + residual\n",
    "\n",
    "        # 畳み込みモジュールを最初に適用しなかった場合、ここでそれを行います。\n",
    "        if not self.convolution_first:\n",
    "            x = self._apply_convolution(x)\n",
    "\n",
    "        # 入力データを保存します。これは後で残差接続を作成するために使用されます。\n",
    "        residual = x\n",
    "        # 二番目のフィードフォワードネットワークを適用します。これにより、畳み込みモジュールとセルフアテンションメカニズムによって\n",
    "        # 処理されたデータが処理され、出力の次元がinput_dimに戻されます。\n",
    "        x = self.ffn2(x)\n",
    "        # スケールされた残差接続を作成します。これは、ネットワークが入力データの重要な情報を保持できるようにするために使用されます。\n",
    "        x = x * 0.5 + residual\n",
    "\n",
    "        # 最終的なレイヤーノーマライゼーションを適用します。これは、出力データのスケールを正規化するために使用されます。\n",
    "        x = self.final_layer_norm(x)\n",
    "        # 処理されたデータを返します。\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca7dcbe6-e1b1-461c-90b3-aac475a10a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LE_Conformer(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        num_heads: int,\n",
    "        ffn_dim: int,\n",
    "        num_layers: int,\n",
    "        depthwise_conv_kernel_size: int,\n",
    "        output_dim,\n",
    "        dropout: float = 0.0,\n",
    "        use_group_norm: bool = False,\n",
    "        convolution_first: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.LE_conformer_layers = torch.nn.ModuleList(\n",
    "            [\n",
    "                LE_ConformerLayer(\n",
    "                    input_dim,\n",
    "                    ffn_dim,\n",
    "                    num_heads,\n",
    "                    depthwise_conv_kernel_size,\n",
    "                    dropout=dropout,\n",
    "                    use_group_norm=use_group_norm,\n",
    "                    convolution_first=convolution_first,\n",
    "                )\n",
    "                for _ in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "        self.li = \n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "\n",
    "\n",
    "        x = input\n",
    "        for layer in self.LE_conformer_layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "437ff5fb-6729-4c2f-b998-f0f36c02e74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 16, 32])\n"
     ]
    }
   ],
   "source": [
    "# LE_Conformerのインスタンスを作成\n",
    "model = LE_Conformer(\n",
    "    input_dim=32,  # 入力の次元数\n",
    "    num_heads=8,  # MultiheadAttentionのヘッド数\n",
    "    ffn_dim=128,  # FeedForwardネットワークの隠れ層の次元数\n",
    "    num_layers=6,  # LE_ConformerLayerの数\n",
    "    depthwise_conv_kernel_size=3,  # Depthwise convolutionのカーネルサイズ\n",
    "    dropout=0.1,  # ドロップアウトの割合\n",
    "    use_group_norm=False,  # GroupNormを使用するかどうか\n",
    "    convolution_first=False  # 畳み込みを最初に行うかどうか\n",
    ")\n",
    "\n",
    "# ダミーデータを生成\n",
    "seq_length = 10  # シーケンスの長さ\n",
    "batch_size = 16  # バッチサイズ\n",
    "input_dim = 32  # 入力の次元数\n",
    "x = torch.randn(seq_length, batch_size, input_dim)\n",
    "\n",
    "# forwardメソッドを呼び出す\n",
    "output = model(x)\n",
    "\n",
    "# 出力の形状を表示\n",
    "print(output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c865568-dc62-4645-8e49-65e0adb77b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "class _ConvolutionModule(torch.nn.Module):\n",
    "    r\"\"\"LE_Conformer convolution module.\n",
    "\n",
    "    Args:\n",
    "        input_dim (int): input dimension.\n",
    "        num_channels (int): number of depthwise convolution layer input channels.\n",
    "        depthwise_kernel_size (int): kernel size of depthwise convolution layer.\n",
    "        dropout (float, optional): dropout probability. (Default: 0.0)\n",
    "        bias (bool, optional): indicates whether to add bias term to each convolution layer. (Default: ``False``)\n",
    "        use_group_norm (bool, optional): use GroupNorm rather than BatchNorm. (Default: ``False``)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,  # 入力の次元数\n",
    "        num_channels: int,  # 畳み込み層のチャンネル数\n",
    "        depthwise_kernel_size: int,  # 深さ方向の畳み込みのカーネルサイズ\n",
    "        dropout: float = 0.0,  # ドロップアウトの割合\n",
    "        bias: bool = False,  # バイアス項を使用するかどうか\n",
    "        use_group_norm: bool = False,  # GroupNormを使用するかどうか\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        # depthwise_kernel_sizeが奇数でなければならない理由は、'SAME'パディングを実現するためです。\n",
    "        if (depthwise_kernel_size - 1) % 2 != 0:\n",
    "            raise ValueError(\"depthwise_kernel_size must be odd to achieve 'SAME' padding.\")\n",
    "        # LayerNorm層\n",
    "        self.layer_norm = torch.nn.LayerNorm(input_dim)\n",
    "        # 畳み込み層と活性化関数を含むシーケンシャルなネットワーク\n",
    "        self.sequential = torch.nn.Sequential(\n",
    "            # Pointwise convolution: 入力次元から2倍のチャンネル数へ\n",
    "            torch.nn.Conv1d(\n",
    "                input_dim,\n",
    "                2 * num_channels,\n",
    "                kernel_size=1, # カーネルサイズ1はPointwiseConvの特徴\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "                bias=bias,\n",
    "            ),\n",
    "            # GLU活性化関数: チャンネル数を半分にする\n",
    "            torch.nn.GLU(dim=1),\n",
    "            # Depthwise convolution: 各チャンネル内での畳み込みを行う\n",
    "            torch.nn.Conv1d(\n",
    "                num_channels,\n",
    "                num_channels,\n",
    "                depthwise_kernel_size,\n",
    "                stride=1,\n",
    "                padding=(depthwise_kernel_size - 1) // 2,\n",
    "                groups=num_channels,\n",
    "                bias=bias,\n",
    "            ),\n",
    "            # GroupNormまたはBatchNorm層\n",
    "            torch.nn.GroupNorm(num_groups=1, num_channels=num_channels)\n",
    "            if use_group_norm\n",
    "            else torch.nn.BatchNorm1d(num_channels),\n",
    "            # SiLU活性化関数\n",
    "            torch.nn.SiLU(),\n",
    "            # Pointwise convolution: チャンネル数を元の入力次元に戻す\n",
    "            torch.nn.Conv1d(\n",
    "                num_channels,\n",
    "                input_dim,\n",
    "                kernel_size=1, # カーネルサイズ1はPointwiseConvの特徴\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "                bias=bias,\n",
    "            ),\n",
    "            # ドロップアウト層\n",
    "            torch.nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        r\"\"\"\n",
    "        Args:\n",
    "            input (torch.Tensor): with shape `(L,B, D)`.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: output, with shape `(L,B, D)`.\n",
    "        \"\"\"\n",
    "        x = self.layer_norm(input)\n",
    "        x = x.permute(1, 2,0) # 1D Convはlengthで畳み込みたい、Dはチャネルとしたいので(B,D,L)とする。\n",
    "        x = self.sequential(x)\n",
    "        return x.permute(2,0,1) #(L,B, D)に戻す。\n",
    "class SEBlock1D(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SEBlock1D, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "class Conv1DBlockWithSE(nn.Module):\n",
    "    def __init__(self, in_channels, depthwise_kernel_size):\n",
    "        super().__init__()\n",
    "        self.layer_norm = torch.nn.LayerNorm(in_channels)\n",
    "        self.conv = nn.Conv1d(in_channels, in_channels, \n",
    "                depthwise_kernel_size,\n",
    "                stride=1,\n",
    "                padding=(depthwise_kernel_size - 1) // 2,)\n",
    "        self.bn = nn.BatchNorm1d(in_channels)\n",
    "        self.swish = nn.SiLU()\n",
    "        self.se = SEBlock1D(in_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer_norm(x)\n",
    "        x = x.permute(1, 2, 0)\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.swish(x)\n",
    "        x = self.se(x)\n",
    "        x = x.permute(2, 0, 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class _FeedForwardModule(torch.nn.Module):# こちらは特に迷うこともなく論文そのままなのでコメントは割愛\n",
    "    r\"\"\"Positionwise feed forward layer.\n",
    "\n",
    "    Args:\n",
    "        input_dim (int): input dimension.\n",
    "        hidden_dim (int): hidden dimension.\n",
    "        dropout (float, optional): dropout probability. (Default: 0.0)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim: int, hidden_dim: int, depthwise_kernel_size: int, dropout: float = 0.0) -> None:\n",
    "        super().__init__()\n",
    "        self.layer_norm = nn.LayerNorm(input_dim)\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.activation = Conv1DBlockWithSE(hidden_dim,depthwise_kernel_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(hidden_dim, input_dim)\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        input = self.layer_norm(input)\n",
    "        hidden = self.fc1(input)\n",
    "        hidden = self.activation(hidden)\n",
    "        hidden = self.dropout(hidden)\n",
    "        output = self.fc2(hidden)\n",
    "        return output\n",
    "\n",
    "class LE_ConformerLayer(torch.nn.Module):\n",
    "    r\"\"\"LE_Conformer layer that constitutes LE_Conformer.\n",
    "\n",
    "    Args:\n",
    "        input_dim (int): input dimension.\n",
    "        ffn_dim (int): hidden layer dimension of feedforward network.\n",
    "        num_attention_heads (int): number of attention heads.\n",
    "        depthwise_conv_kernel_size (int): kernel size of depthwise convolution layer.\n",
    "        dropout (float, optional): dropout probability. (Default: 0.0)\n",
    "        use_group_norm (bool, optional): use ``GroupNorm`` rather than ``BatchNorm1d``\n",
    "            in the convolution module. (Default: ``False``)\n",
    "        convolution_first (bool, optional): apply the convolution module ahead of\n",
    "            the attention module. (Default: ``False``)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        ffn_dim: int,\n",
    "        num_attention_heads: int,\n",
    "        depthwise_conv_kernel_size: int,\n",
    "        dropout: float = 0.0,\n",
    "        use_group_norm: bool = False,\n",
    "        convolution_first: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # 最初のフィードフォワードネットワークを定義します。このネットワークは、入力データを処理し、\n",
    "        # 隠れ層の次元をffn_dimに変換します。\n",
    "        self.ffn1 = _FeedForwardModule(input_dim, ffn_dim, depthwise_conv_kernel_size, dropout=dropout)\n",
    "\n",
    "        # レイヤーノーマライゼーションを定義します。これは、入力データのスケールを正規化するために使用されます。\n",
    "        self.self_attn_layer_norm = torch.nn.LayerNorm(input_dim)\n",
    "        # セルフアテンションメカニズムを定義します。これは、入力データの各部分が他の部分とどの程度関連しているかを学習します。\n",
    "        self.self_attn = torch.nn.MultiheadAttention(input_dim, num_attention_heads, dropout=dropout)\n",
    "        # ドロップアウトを定義します。これは、ネットワークの過学習を防ぐために使用されます。\n",
    "        self.self_attn_dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "        # 畳み込みモジュールを定義します。これは、入力データに畳み込みを適用し、特徴を抽出します。\n",
    "        self.conv_module = _ConvolutionModule(\n",
    "            input_dim=input_dim,\n",
    "            num_channels=input_dim,\n",
    "            depthwise_kernel_size=depthwise_conv_kernel_size,\n",
    "            dropout=dropout,\n",
    "            bias=True,\n",
    "            use_group_norm=use_group_norm,\n",
    "        )\n",
    "\n",
    "        # 二番目のフィードフォワードネットワークを定義します。このネットワークは、畳み込みモジュールとセルフアテンションメカニズムによって\n",
    "        # 処理し、出力の次元をinput_dimに戻します。\n",
    "        self.ffn2 = _FeedForwardModule(input_dim, ffn_dim, depthwise_conv_kernel_size, dropout=dropout)\n",
    "        # 最終的なレイヤーノーマライゼーションを定義します。これは、出力データのスケールを正規化するために使用されます。\n",
    "        self.final_layer_norm = torch.nn.LayerNorm(input_dim)\n",
    "        # 畳み込みモジュールをセルフアテンションメカニズムの前に適用するかどうかを決定します。\n",
    "        self.convolution_first = convolution_first\n",
    "\n",
    "    def _apply_convolution(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        # 入力データを保存します。これは後で残差接続を作成するために使用されます。\n",
    "        residual = input\n",
    "        # 入力データの次元を変更します。これは、畳み込みモジュールが適切に機能するために必要です。\n",
    "        input = input.transpose(0, 1)\n",
    "        # 畳み込みモジュールを適用します。これにより、入力データに畳み込みが適用され、特徴が抽出されます。\n",
    "        input = self.conv_module(input)\n",
    "        # 入力データの次元を元に戻します。これは、後続の処理ステップが適切に機能するために必要です。\n",
    "        input = input.transpose(0, 1)\n",
    "        # 残差接続を作成します。これは、ネットワークが入力データの重要な情報を保持できるようにするために使用されます。\n",
    "        input = residual + input\n",
    "        return input\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        r\"\"\"\n",
    "        Args:\n",
    "            input (torch.Tensor): input, with shape `(T, B, D)`.\n",
    "            key_padding_mask (torch.Tensor or None): key padding mask to use in self attention layer.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: output, with shape `(T, B, D)`.\n",
    "        \"\"\"\n",
    "        # 入力データを保存します。これは後で残差接続を作成するために使用されます。\n",
    "        residual = input\n",
    "        # 最初のフィードフォワードネットワークを適用します。これにより、入力データが処理され、隠れ層の次元がffn_dimに変換されます。\n",
    "        x = self.ffn1(input)\n",
    "        # スケールされた残差接続を作成します。これは、ネットワークが入力データの重要な情報を保持できるようにするために使用されます。\n",
    "        x = x * 0.5 + residual\n",
    "\n",
    "        # 畳み込みモジュールを最初に適用する場合、ここでそれを行います。\n",
    "        if self.convolution_first:\n",
    "            x = self._apply_convolution(x)\n",
    "\n",
    "        # 入力データを保存します。これは後で残差接続を作成するために使用されます。\n",
    "        residual = x\n",
    "        # レイヤーノーマライゼーションを適用します。これは、入力データのスケールを正規化するために使用されます。\n",
    "        x = self.self_attn_layer_norm(x)\n",
    "        # セルフアテンションメカニズムを適用します。これは、入力データの各部分が他の部分とどの程度関連しているかを学習します。\n",
    "        x, _ = self.self_attn(\n",
    "            query=x,\n",
    "            key=x,\n",
    "            value=x,\n",
    "            need_weights=False,\n",
    "            \n",
    "        )\n",
    "        # ドロップアウトを適用します。これは、ネットワークの過学習を防ぐために使用されます。\n",
    "        x = self.self_attn_dropout(x)\n",
    "        # 残差接続を作成します。これは、ネットワークが入力データの重要な情報を保持できるようにするために使用されます。\n",
    "        x = x + residual\n",
    "\n",
    "        # 畳み込みモジュールを最初に適用しなかった場合、ここでそれを行います。\n",
    "        if not self.convolution_first:\n",
    "            x = self._apply_convolution(x)\n",
    "\n",
    "        # 入力データを保存します。これは後で残差接続を作成するために使用されます。\n",
    "        residual = x\n",
    "        # 二番目のフィードフォワードネットワークを適用します。これにより、畳み込みモジュールとセルフアテンションメカニズムによって\n",
    "        # 処理されたデータが処理され、出力の次元がinput_dimに戻されます。\n",
    "        x = self.ffn2(x)\n",
    "        # スケールされた残差接続を作成します。これは、ネットワークが入力データの重要な情報を保持できるようにするために使用されます。\n",
    "        x = x * 0.5 + residual\n",
    "\n",
    "        # 最終的なレイヤーノーマライゼーションを適用します。これは、出力データのスケールを正規化するために使用されます。\n",
    "        x = self.final_layer_norm(x)\n",
    "        # 処理されたデータを返します。\n",
    "        return x\n",
    "\n",
    "class LE_Conformer(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        num_heads: int,\n",
    "        ffn_dim: int,\n",
    "        num_layers: int,\n",
    "        depthwise_conv_kernel_size: int,\n",
    "        dropout: float = 0.0,\n",
    "        use_group_norm: bool = False,\n",
    "        convolution_first: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.LE_conformer_layers = torch.nn.ModuleList(\n",
    "            [\n",
    "                LE_ConformerLayer(\n",
    "                    input_dim,\n",
    "                    ffn_dim,\n",
    "                    num_heads,\n",
    "                    depthwise_conv_kernel_size,\n",
    "                    dropout=dropout,\n",
    "                    use_group_norm=use_group_norm,\n",
    "                    convolution_first=convolution_first,\n",
    "                )\n",
    "                for _ in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "\n",
    "\n",
    "        x = input\n",
    "        for layer in self.LE_conformer_layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066a1151-6124-4119-9826-e76ad97ae955",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
